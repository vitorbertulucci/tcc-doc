\chapter[Fundamentação Teórica]{Fundamentação Teórica}

O estudo de Inteligência Artificial vem sendo cada vez mais comum na comunidade de tecnologia da informação para a criação de sistemas que buscam automatizar e auxiliar de maneira mais eficiente o trabalho humano. O ramo de aplicação para essa tecnologia é imensa, e o uso para a área do Direito não seria diferente.

\section{Aprendizagem de Máquina}

Aprendizado de Máquina do inglês \textit{Machine Learning} (ML) é uma das subáreas da Inteligência Artificial que visa criar mecanismos que possibilitem fazer com que uma máquina possa "aprender" sobre um determinado problema a partir de um conjunto de dados de entrada. Em outras palavras, ML permite que um dado algoritmo desenvolva uma função matemática que consiga representar tal conjunto de dados. Com essa função ou modelo matemático, é possível agora realizar inferências sobre outros dados, desde que esses sejam relacionados à mesma problemática \cite{deep-learning-book}.

O processo de aprendizagem se da início a partir de observações ou dados, como exemplos, experiência direta ou instruções que possibilitem identificar padrões do dado para realizar e atingir melhores decisões em futuras apresentações ou exemplos de dados que possam ser fornecidas. Dentro do processo de permitir que uma máquina aprenda, existem três áreas as quais os mecanismos de aprendizagem são classificados \cite{python-ml}:

\begin{itemize}
  \item \textbf{Aprendizado supervisionado:} o objetivo principal de algoritmos supervisionados é conseguir desenvolver um modelo matemático a partir de um conjunto de dados anotados, no caso, dados de treinamento. O \textit{supervisionado} diz respeito ao conjunto de dados os quais já se sabe a saída esperada, ou seja, o dado já é anotado previamente. Em geral, esses algoritmos são utilizados para problemas de classificação e regressão.

  % fonte: https://blogs.nvidia.com/blog/2018/08/02/supervised-unsupervised-learning/

  \begin{figure}
    \includegraphics[width=\linewidth]{figuras/nvidia-supervised-learning.png}
    \caption{Aprendizado supervisionado \color{red} OBS: COLOCAR FONTE}
    \label{fig:nvidia-supervised-learning}
  \end{figure}
  \newpage
  \item \textbf{Aprendizado não supervisionado:} diz respeito aos métodos de aprendizagem de máquina os quais utiliza-se como dado de entrada um dado que não possui nenhum tipo de anotação e que, muitas vezes, sua estrutura é desconhecida.

  Tal processo de aprendizagem permite extrair características relevantes sobre o dado que possam servir de insumo para uma futura categorização e classificação do mesmo. Dependendo do problema em questão, a aprendizagem supervisionada pode organizar o dado em diferentes categorias \cite{learning-types} como clusterização, associação, \textit{autoencoders}, \textit{anomaly detection}, etc.

  \item \textbf{Aprendizado semi-supervisionado:} já o aprendizado semi-supervisionado junta um pouco dos dois mundos: dados com registros anotados e também dados com registros não anotados. A aplicabilidade para esse tipo de aprendizagem é quando se possui um dado onde não é trivial extrair informações relevantes sobre ele e tampouco é realizar toda a anotação da amostra em questão \cite{learning-types}.
\end{itemize}

Dentro dos tipos de algoritmos que podem ser utilizados para construir ML, um que é bastante notado, se não o mais conhecido, são as chamadas Redes Neurais Artificiais ou \textit{Neural Networks} (NN). Diferentemente de \textit{Machine Learning}, as NN é um campo dentro de ML que possiblita o aprendizado de máquina tentando imitar o comportamento dos neurônios humanos \cite{neural-net-history}.

\subsection{\textit{Neural Networks}}

Em 1943, Warren McCulloch e Walter Pitts em seu artigo \textit{A Logical Calculus of the Ideas Immanent in Nervous Activity} desenvolveram um estudo para tentar explicar como o cérebro consegue reconhecer um nível complexo de padrões por meio dos neurônios \cite{first-neuron-study}, desenvolvendo um modelo chamado MCP, que atualmente é conhecido como o ancestral das redes neurais artificiais \cite{dl-brief-review}. Tal estudo possibilitou dar-se o pontapé para a evolução das redes neurais que conhecemos hoje.

Na década de 1950 surgiu então o modelo de \textit{Perceptron} \cite{perceptron}, que é a primeira rede neural formalmente desenvolvida composta de apenas uma única camada, descrito como um modelo matemático que recebe várias entradas e produz uma saída binária.

% fonte da imagem: https://towardsdatascience.com/the-perceptron-3af34c84838c

\begin{figure}[h]
  \includegraphics[width=13cm, center]{figuras/perceptron}
  \caption{O \textit{Perceptron} \color{red} OBS: COLOCAR FONTE}
  \label{fig:perceptron}
\end{figure}

Cada entrada ou \textit{input} representa um dado de entrada que são inseridos diretamente nos nós de entrada ou \textit{input nodes}, representados pela letra \(x\). Cada um desses nós representam separadamente uma característica do dado de entrada. Na figura \ref{fig:perceptron}, a quantidade de características é delimitada pela letra \(m\) e o intervalo de características é dado por [1, \(m\)]. A camada caracterizada pelas letras \textit{x} é chamada de camada de entrada ou \textit{input layer}. Redes Neurais só podem receber como entrada valores numéricos \cite{deep-learning-book}.

É importante reparar na figura \ref{fig:perceptron} que todo nó da camada de entrada está diretamente associado com uma seta caracterizada pela letra \(w\), também de intervalo [1, \(m\)]. Tais letras caracterizam o que é conhecido como os pesos ou \textit{weights}. Tais setas são chamadas de sinapses\footnote
{
  Na biologia, sinapse é a região localizada entre os neurônios e agem como neurotransmissores, responsáveis por realizar a transferência de inpulso nervoso de um neurônio para o outro \cite{synapses}.
}.
Essa região é definida como camada de pesos ou \textit{weight layer}.

Por fim, tem-se o nó de maior tamanho definido pela letra \(y\), conhecido como nó de saída ou \textit{output node}. Esse nó realiza um cálculo baseado em \textit{score} sobre os valores de entrada e peso e por meio de uma função de ativação, gera uma predição \textit{output} de 0 ou 1 sobre o valor resultante do \textit{score}.

A função matemática que define o valor encontrado em \(y\) é:

\[ f(y) = \sum_{i=1}^{m} x_iw_i \]

onde a função de ativação consome o valor resultante da função \(f(y)\).

\subsubsection{Função de Ativação}

\subsubsection{Forward pass}

\subsubsection{Backpropagation}

\subsubsection{Hiperparâmetros}

\subsection{Discriminativo vs Generativo}

\section{OCR}