\chapter[Materiais e métodos]{Materiais e métodos}

\hl{ADICIONAR DESC. INICIAL}

\section{O dado}

Como dito, existem diversos tipos de áreas de desenvolvimento que caracterizam a Inteligência Artificial. A área de \textit{machine learning} é caracterizada pela capacidade da máquina aprender a partir de experiências com o dado, por isso deve-se dar uma enorme importância para a qualidade do dado para conseguir resolver problemas com ML, mais ainda para \textit{Deep Learning}. Para ser possível a construção de um modelo que visa testar a hipótese de estudo em questão, seria necessário realizar o levantamento de um conjunto de dados em formato de texto, em português, que fosse possível alimentar o modelo a ser criado.

O Grupo de Pesquisa em Aprendizado de Máquina (GPAM) da Universidade de Brasília desenvolveu em 2018 um projeto de pesquisa que visa realizar a classificação das repercussões gerais do Supremo Tribunal Federal (STF) \cite{cnn-for-STF}. Para essa classificação, o projeto precisava realizar a extração de informações dos textos das decisões judiciais do STF, sendo essas possuindo documentos digitais tanto formulados digitalmente, manuscritos e/ou escaneados. Tal conjunto de dados foi fornecido para o presente trabalho de conclusão a fim de facilitar o processo de aquisição dos mesmos por meio de \textit{crawlers}\footnote{
  \textit{Crawlers} ou \textit{web crawlers} são tecnologias que possibilitam a extração de informações disponíveis em sites da Internet de maneira organizada para possibilitar o consumo desses dados para desenvolvimento de algoritmos. Bastante comum para criação de base de dados de ML.
} ou outras fontes.

\subsection{Características}

Foram fornecidos 89.578 processos do Supremo Tribunal Federal em formato PDF, contendo os diversos temas de repercussões gerais e diferentes características \cite{cnn-for-STF}. Algumas delas são:

\begin{itemize}
  \item O STF recebe processos em segunda instância de todo o Brasil e não existe nenhum padrão em sua formatação, fonte, espaçamento e escrita;
  \item Uma parte significante dos documentos fornecidos estão em forma de imagem obtidas por meio de \textit{scanners} e muitas vezes possui anotações, estampas, marcas d'agua, manchas, sombras, etc.
\end{itemize}


No projeto desenvolvido, o GPAM realizou um conjunto de extrações e formatações dos documentos para facilitar o trabalho a partir de uma etapa de processamento.

\begin{figure}[H]
  \includegraphics[width=13cm, center]{figuras/gpan-pipeline.png}
  \caption{Fluxo de processamento de processos do STF pelo GPAM.}
  \label{fig:gpan-pipeline}
\end{figure}

Nesse processamento, uma das etapas consistiu em verificar se a página do documento possui texto selecionável ou não, para então realizar a extração do texto via algoritmo de OCR. Tudo isso foi armazenado em um arquivo CSV, cuja as principais estão descritas a seguir.

% process_id,,,,,document_id,,,page_is_ocr,,page_text_extract,page_number,,

\begin{table}[h]
 \centering
 \caption{Principais características do dado CSV}
 \begin{tabular}{|m{9em}|m{20em}|}
    \hline
      \textbf{Coluna}  &
      \textbf{Descrição} \\
    \hline
      \textit{process\_id}  &
      Parte do número do processo no tribunal \\
    \hline
      \textit{document\_id}  &
      Identificador do documento dentro do processo \\
    \hline
      \textit{page\_is\_ocr}  &
      Booleano definindo se a página necessita de OCR \\
    \hline
      \textit{page\_text\_extract} &
      Texto extraído da página utilizando OCR \\
    \hline
      \textit{page\_number} &
      Número da página do PDF a qual aquela extração pertence \\
    \hline
 \end{tabular}
 \label{tab:csv-details}
\end{table}

É importante notar que os campos \textit{process\_id} e \textit{document\_id} se repetem no CSV mas a junção de ambos juntamente com a \textit{page\_number} identificam unicamente a página dentro do PDF.

\subsection{Tratamento e formação do \textit{dataset}}

Por se tratar de uma problemática diferente do GPAM, foi preciso consumir o que foi fornecido e gerar novos dados que se encaixem melhor para a solução. Para tal, criou-se um conjunto de algoritmos para pegar os dados e realizar essa adequação no formato de uma \textit{pipeline}\footnote{
  Na computação, o termo \textit{pipeline} define um conjunto de processamentos de dados conectados em série, onde a saída de um desses elementos de processamento é a entrada do próximo, sendo elas dependentes para o processamento ser executado adequadamente.
}, com etapas de separação de documentos que possuem páginas que necessitam de OCR, extração de imagem a partir de PDF, criação de filtros de imagem e extração de informação de imagem utilizando o OCR.

\begin{figure}[H]
  \includegraphics[width=\linewidth, rotate=0, center]{figuras/crappy-flow-diagram.png}
  \caption{Processo para a criação de \textit{dataset}.}
\end{figure}

\subsubsection{Separação de documentos}
O conjunto de PDFs fornecidos como dados estavam todos juntos em um único diretório no disco, sem a correta divisão de qual era o dado contido no PDF. O CSV fornecido pelo GPAN e os itens descritos na tabela \ref{tab:csv-details} fazem referência a todas as páginas desses PDFs e possui também o seu conteúdo, sendo eles extraídos por meio de OCR ou não, como mostra a figura \ref{fig:gpan-pipeline}. Porém como o foco do trabalho é realizar estudos sobre a qualidade do OCR, decidiu-se por separar o dado entre os que foram extraídos utilizando OCR dos que não foram.

Para isso, gerou-se um novo CSV apenas com os registros de páginas cujo necessitou-se do OCR em sua extração e criou-se também um diretório para armazenar apenas os PDFs que possuíam páginas não-selecionáveis. Dos 89.578 arquivos, existem cerca de 354.501 páginas somadas, sendo essas:

\begin{table}[H]
  \centering
  \caption{Quantidade de cada tipo de página dos PDFs.}
  \begin{tabular}{|m{10em}|c|}
    \hline
      \textbf{Tipo}  &
      \textbf{Quantidade} \\
    \hline
      Necessita de OCR  &
      80.624 \\
    \hline
      Não necessita de OCR  &
      273.877 \\
    \hline
      \textbf{TOTAL}  &
      \textbf{354.501} \\
    \hline
  \end{tabular}
  \label{tab:csv-diff}
\end{table}

\subsubsection{Extração de imagem do PDF}
Com os dados separados em um diretório específico, iniciou-se a etapa de extração de imagem a partir dos documentos em formato PDF dos processos. Utilizou-se também informações do CSV (tabela \ref{tab:csv-details}) para selecionar a página específica do documento a qual o OCR foi utilizado, diminuindo assim o tempo de processamento por documento.

A extração de imagem a partir do PDF é feita utilizando um algoritmo de software livre desenvolvido em Python, chamado de \textit{pdf2image}. Ele recebe como entrada um PDF e é possível definir qual ou quais páginas do PDF deseja-se extrair, permitindo assim a geração do \textit{dataset} de imagens de processos.

\subsubsection{Aplicação de filtros}
Para a criação de um modelo generativo que consiga diminuir os ruídos de imagens, é preciso utilizar como dado de entrada imagens que possuam tais características - ruídos. Das 354 mil páginas dos PDFs disponíveis, fazer a separação de todas elas para a identificação de imagens ruins deria um trabalho bem complexo e que diminuiria o tempo disponível para o desenvolvimento do presente trabalho. Com isso, adotou-se a heurística de que todas as fotos que tiveram texto extraído via OCR (tabela \ref{tab:csv-diff}) seriam "pioradas" aplicando um conjunto de filtro de imagens de diferentes tipos.

Um filtro de imagem é um algoritmo ou rotina de software que consegue alterar de forma fixa ou aleatória os valores dos pixels contidos em uma imagem. Com isso, é possível criar uma lógica que tente simular imagens escaneadas de maneira automatizada, aplicando sombreamento, borrões, manchas, distorções, etc.


\begin{figure}[H]
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=0.8\linewidth]{figuras/good-text-image.jpg}
    \caption{Foto sem filtro}
    \label{fig:image-without-filter}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=0.8\linewidth]{figuras/image-with-overlay.jpg}
    \caption{Foto com filtro aplicado}
    \label{fig:image-with-filter}
  \end{subfigure}
  \caption{A figure with two subfigures}
  \label{fig:side-process-images}
\end{figure}

Existem diversas bibliotecas já implementadas em Python que possibilitam a aplicação de filtros em imagens. As utilizadas foram: \textit{ImageFilter} da biblioteca \textit{Python Imaging Library} e \textit{imgaug}, biblioteca de \textit{data augmentation}\footnote{
  Processo de transformação do dado que permite que seu tamanho cresca, fornecendo assim mais insumos ou entradas de dados disponíveis em um processo de treinamento.
}. Alguns filtros foram de origem autoral.

Abaixo, listam-se todos os filtros utilizados e estudados para o presente processamento de imagem.

\begin{table}[H]
  \centering
  \caption{Quantidade de cada tipo de página dos PDFs.}
  \begin{tabular}{|m{.2\linewidth}|m{.2\linewidth}|m{.5\linewidth}|}
    \hline
      \textbf{Nome}  &
      \textbf{Fonte}  &
      \textbf{Descrição} \\
    \hline
      Necessita de OCR  &
      Necessita de OCR  &
      80.624 \\
    \hline
      Não necessita de OCR  &
      Não necessita de OCR  &
      273.877 \\
    \hline
      \textbf{TOTAL}  &
      \textbf{TOTAL}  &
      \textbf{354.501} \\
    \hline
  \end{tabular}
  \label{tab:sdas}
\end{table}

\subsubsection{Extração de texto via OCR}

\section{Método proposto}