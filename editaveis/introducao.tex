\chapter[Introdução]{Introdução}
% \addcontentsline{toc}{chapter}{Introdução}

A automação com a informatização dos processos judiciais vem sendo utilizado, atualizado e evoluido nos Estados Unidos desde os anos 90 \cite{automating-judicial-doc} e, no Brasil, a partir de 2006 com a publicação da Lei nº 11.419. Essa lei permitiu não só a tramitação de processos judiciais em ambientes eletrônicos \cite{digitalizacao-de-proc-judiciais} como também possibilitou informatizar qualquer forma de armazenamento e tráfego de informações referentes aos processos em arquivos digitais.

Em 2010, o Superior Tribunal de Justiça tornou-se o primeiro tribunal brasileiro totalmente virtualizado com todos os seus processos disponíveis em plataformas online \cite{digitalizacao-de-proc-judiciais}, onde a maior parte desses processos foi transferida para a plataforma lançada oficialmente em 2011 pelo Conselho Nacional de Justiça (CNJ), o Processo Judicial Eletrônico, comumente chamado de PJe. A plataforma permitiu não só facilitar o trabalho dos advogados, juízes, procuradores e estagiários com a sua mudança de paradigma de trabalho como também auxiliou na diminuição do tempo de duração de boa parte dos processos \cite{pje-diminuicao-tempo-do=proc}, que, segundo o CNJ em seu relatório \textit{Justiça em Números} de 2018, o tempo de vida médio dos processos podem chegar a 7 anos e 11 meses na fase de execução da Justiça Federal.

% review this
Contudo, a adoção de um modelo mais inovador de trabalho para o ramo jurídico não soluciona o problema de criação de novos processos físicos nem dos processos físicos ainda em vigência e, por isso, é necessário uma etapa de digitalização dos mesmos. Nessa atividade, manual e exaustiva, é preciso passar os documentos por \textit{scanners} para permitir o uso dos processos em sistemas digitais, como o PJe, sem contar que com isso, o processo passa a ser digitalizado
    \footnote{
        O processo de digitalização ocorre na etapa de transformação de um sinal analógico para um sinal digital. Consiste em tornar uma informação disponível fisicamente para que essa possa ser acessada em um meio digital.
    }.

A partir disso, utiliza-se uma tecnologia denominada \textit{Optical Character Recognition} ou OCR onde, tendo os documentos digitalizados, extraem-se os textos dos mesmos, permitindo que possam ser colocados em documentos totalmente digitais. Porém, tal tecnologia precisa de uma imagem limpa e clara do conteúdo nela presente, o que nem sempre é realidade. A principal problemática dos processamentos de imagem para a extração de texto se dá pela dificuldade de manter os documentos digitalizados com informações limpas e sem ruídos.

\newpage

\section{Objetivo}

Tendo em vista a problemática apresentada a respeito do processo de informatização dos documentos jurídicos, o objetivo principal desse trabalho de conclusão de curso é a criação de algoritmo que pode vir a auxiliar as tecnologias de OCR a alcançarem melhores resultados, criando uma etapa de pré-processamento para melhorar as imagens disponíveis. Essa melhoria é baseada em criar uma nova imagem a partir de imagens ruins ou com ruídos, corrigindo assim os pontos na imagem que influenciariam negativamente na qualidade final no reconhecimento de caractéres pelo OCR, refundando a seguinte hipótese:

\begin{quote}
  O uso de Aprendizado de Máquina permite desenvolver modelos de redução de ruídos capazes, de maneira eficaz e eficiente, aprimorar positivamente na qualidade do texto extraído via OCR.
\end{quote}

Dentre as diversas técnicas de \textit{Machine Learning} existentes, o \textit{Deep Learning} vem sendo provado como um excelente método para o campo de visão computacional \cite{dl-brief-review}. Utilizando esse tipo de técnica é possível desenvolver algoritmos que criem novas imagens a partir de imagens ruins de documentos digitalizaos - problema em questão - e consiga manter as mesmas características, possivelmente corrigindo os ruídos que afetam negativamente o OCR e melhorando assim a qualidade da imagem e clareza de suas informações.

Esse modelo é baseado em Redes Neurais Artificiais para a criação de um modelo generativo, onde, diferentemente dos modelos discriminativos, o dado de saída é uma nova imagem gerada e não uma classificação do dado de entrada. Com isso, a hipótese do estudo de caso é que a partir das imagens geradas pelo modelo, o processamento de imagem pelo OCR atinja melhores resultados.

\section{Método}

O método de trabalho a ser desenvolvido para a presente hipótese do problema consiste em desenvolver um modelo de \textit{Deep Learning}, mais especificamente uma Rede Neural Artificial - do ingês \textit{Artificial Neural Network} - que possibilite construir uma Inteligência Artificial capaz de gerar novas imagens a partir de imagens ruins ou com ruídos. Com isso, será possível generalizar o modelo que, independente da imagem de texto inserida nele, o mesmo possa criar uma nova imagem com menos ruídos e mais limpa do que a imagem de entrada.

O \textit{dataset} disponível para o treinamento, teste e validação dos modelos a serem construídos são provenientes de extrações dos processos do Supremo Tribunal Federal adquiridos pelos alunos de projeto de pesquisa do laboratório GPAM da Universidade de Brasília. Tal acervo conta com aproximadamente 90 mil documentos em formato PDF.

Tendo esses documentos em formato PDF como base, os mesmos passarão por um algoritmo de transformação de PDF para Imagem em escala preto e branco e aplicando então um processamento de extração de texto de imagens por meio de OCR. Dado o resultado do OCR das imagens boas em mãos, é possível agora "estragar" programaticamente as imagens, adicionando ruídos nas mesmas para que o OCR dessas fotos ruins possam ser diferentes - e piores - do que o resultado apresentado no reconhecimento de caracteres anteriores.

Com a diferença dos dois OCRs, em imagens boas e ruins, serão geradas então novas imagens que visam alcançar ou ficar o mais próximo possível dos resultados atingidos pelo OCR nas imagens boas. A hipótese então, de conseguir melhorar o resultado de reconhecimento de caracteres pelo processamento de imagens a partir da criação de um modelo generativo capaz de corrigir defeitos em imagens de texto ruins, poderá ser experimentada e validada.

Essa experimentação, em caso de sucesso, permitirá construir um algoritmo capaz de ser acoplado aos processamentos de imagens e digitalizações para melhorar a qualidade de qualquer documento digitalizado, permitindo que a clareza e nitidez das informações neles apresentada sejam melhores do que as que são atualmente alcançadas por \textit{softwares} convecionais.

% Este documento apresenta considerações gerais e preliminares relacionadas
% à redação de relatórios de Projeto de Graduação da Faculdade UnB Gama
% (FGA). São abordados os diferentes aspectos sobre a estrutura do trabalho,
% uso de programas de auxilio a edição, tiragem de cópias, encadernação, etc.

% Este template é uma adaptação do ABNTeX2\footnote{\url{https://github.com/abntex/abntex2/}}.
